{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import gluoncv as gcv\n",
    "from gluoncv.data import VOCDetection\n",
    "# typically we use 2007+2012 trainval splits for training data\n",
    "train_dataset = VOCDetection(splits=[(2007, 'trainval'), (2012, 'trainval')])\n",
    "# and use 2007 test as validation data\n",
    "val_dataset = VOCDetection(splits=[(2007, 'test')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from gluoncv.data.transforms import presets\n",
    "from gluoncv import utils\n",
    "from mxnet import nd\n",
    "\n",
    "width, height = 416, 416  # resize image to 416x416 after all data augmentation\n",
    "train_transform = presets.yolo.YOLO3DefaultTrainTransform(width, height)\n",
    "val_transform = presets.yolo.YOLO3DefaultValTransform(width, height)\n",
    "\n",
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from mxnet.gluon.data import DataLoader\n",
    "\n",
    "batch_size = 5  # for tutorial, we use smaller batch-size\n",
    "num_workers = 0  # you can make it larger(if your CPU has more cores) to accelerate data loading\n",
    "\n",
    "# behavior of batchify_fn: stack images, and pad labels\n",
    "batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset.transform(val_transform), batch_size, shuffle=False,\n",
    "                        batchify_fn=batchify_fn, last_batch='keep', num_workers=num_workers)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "batch: \n",
      " ",
      "(\n[[[[-2.0781863  -2.0867932  -2.1016858  ... -2.0924532  -2.110679\n    -2.1217976 ]\n   [-2.082326   -2.0919385  -2.1083825  ... -2.102681   -2.113593\n    -2.1203184 ]\n   [-2.0907009  -2.099584   -2.1145532  ... -2.117129   -2.1177082\n    -2.1182153 ]\n   ...\n   [ 0.1587951   0.1705039   0.1909194  ... -1.1928699  -1.0560479\n    -0.9681952 ]\n   [ 0.14921437  0.15044498  0.1518703  ... -1.1236101  -0.9422763\n    -0.82680804]\n   [ 0.14448634  0.13695976  0.12260129 ... -1.0840803  -0.8678288\n    -0.73110235]]\n\n  [[-2.0402267  -2.040413   -2.0414455  ... -2.0219479  -2.0318546\n    -2.0382063 ]\n   [-2.0295973  -2.0338562  -2.0416274  ... -2.02714    -2.0333095\n    -2.0372605 ]\n   [-2.0140755  -2.0224178  -2.036789   ... -2.034539   -2.0353832\n    -2.0359147 ]\n   ...\n   [ 0.08760366  0.09957328  0.12044462 ... -1.3115871  -1.2079707\n    -1.1408606 ]\n   [ 0.0778088   0.07906675  0.08052415 ... -1.2389289  -1.0907786\n    -0.9958279 ]\n   [ 0.07297537  0.06528092  0.05060168 ... -1.1956303  -1.01125\n    -0.89408493]]\n\n  [[-1.8090729  -1.8002192  -1.7855402  ... -1.8073293  -1.8052583\n    -1.8039619 ]\n   [-1.8087989  -1.8028827  -1.7930585  ... -1.8072647  -1.805243\n    -1.8039964 ]\n   [-1.8084135  -1.8066468  -1.8036773  ... -1.8058043  -1.8048307\n    -1.8042384 ]\n   ...\n   [ 0.3094366   0.32135302  0.34213158 ... -1.5366685  -1.5076319\n    -1.4870188 ]\n   [ 0.29968527  0.30093762  0.30238855 ... -1.467113   -1.4130244\n    -1.377004  ]\n   [ 0.29487333  0.28721306  0.27259907 ... -1.4219598  -1.3449785\n    -1.2952229 ]]]\n\n\n [[[ 2.1254246   2.0249527   2.009661   ...  0.35344774  0.22926289\n     0.33931205]\n   [ 1.897478    2.247933    1.9616045  ...  0.4953492   0.41436732\n     0.12721817]\n   [ 1.2157155   2.4894617   2.2024632  ...  0.40518352  0.36741135\n     0.15085831]\n   ...\n   [ 0.3974154   0.26611495  0.4770339  ...  0.8439877   0.37181768\n    -0.29922548]\n   [ 0.2979964   0.51395625  0.993586   ...  0.85783786  0.2546862\n    -0.1939487 ]\n   [ 0.2588622   0.87653834  1.1162226  ...  0.96580267 -0.08432756\n    -0.06621503]]\n\n  [[ 2.040329    1.9697955   1.9992075  ... -0.8762304  -0.8027403\n    -0.5055038 ]\n   [ 1.9417506   2.2815077   1.9738741  ... -0.7197234  -0.5628984\n    -0.68905693]\n   [ 1.0161103   2.2963514   1.9614266  ... -0.75230306 -0.5486433\n    -0.6017867 ]\n   ...\n   [-0.4329592  -0.43209642 -0.1418085  ... -0.24464047 -0.6074489\n    -1.1881968 ]\n   [-0.39949307 -0.07393623  0.44790483 ... -0.21639146 -0.67448133\n    -0.98870546]\n   [-0.2083306   0.468098    0.7636559  ... -0.10850413 -0.9865074\n    -0.83917207]]\n\n  [[ 2.5374134   2.5143576   2.5914812  ...  0.11528665  0.09367546\n     0.23605931]\n   [ 2.4980462   2.7058866   2.380571   ...  0.21892986  0.25733352\n    -0.03574027]\n   [ 2.1142104   3.2035923   2.7469668  ...  0.1158117   0.12207879\n    -0.05905443]\n   ...\n   [ 0.367267    0.35162756  0.64275944 ...  0.7288317   0.3531587\n    -0.316509  ]\n   [ 0.53872734  0.8111791   1.2781969  ...  0.7095921   0.196696\n    -0.17408107]\n   [ 0.8327727   1.4349602   1.6509603  ...  0.80834645 -0.15736964\n    -0.06844905]]]\n\n\n [[[ 1.9119486   2.0307362   2.1489065  ...  1.7850186   1.7180315\n     1.6154678 ]\n   [ 2.0859408   2.1969955   2.1693437  ...  1.53922     1.5352012\n     1.4414756 ]\n   [ 2.3314483   2.377715    2.364748   ...  1.860256    1.838952\n     1.6983935 ]\n   ...\n   [ 1.5065147   1.4750093   1.4460773  ...  1.486032    1.442962\n     1.427614  ]\n   [ 1.4330074   1.3750776   1.3053256  ...  1.4243053   1.3878876\n     1.318486  ]\n   [ 1.5959524   1.4949389   1.4169014  ...  1.5733684   1.6331779\n     1.4064658 ]]\n\n  [[ 2.0866718   2.1904545   2.3114388  ...  1.9711233   1.9128292\n     1.8078235 ]\n   [ 2.2648077   2.3606727   2.3323631  ...  1.7194715   1.7256451\n     1.6296877 ]\n   [ 2.5074875   2.5456958   2.53242    ...  2.048152    2.0366297\n     1.8927238 ]\n   ...\n   [ 1.7109102   1.6832336   1.6536136  ...  1.2487895   1.2447186\n     1.2614491 ]\n   [ 1.6313151   1.5809222   1.5095098  ...  1.3642317   1.3565882\n     1.2943189 ]\n   [ 1.7981403   1.7036378   1.6237423  ...  1.5924143   1.6711386\n     1.442457  ]]\n\n  [[ 2.2936869   2.4400558   2.5600836  ...  2.1439927   2.0611172\n     1.9569426 ]\n   [ 2.470414    2.6089277   2.5808415  ...  1.8943315   1.875414\n     1.7802159 ]\n   [ 2.7322876   2.7924871   2.7793164  ...  2.2204125   2.183939\n     2.041171  ]\n   ...\n   [ 1.773161    1.734557    1.7051706  ...  0.33834457  0.39318457\n     0.47074014]\n   [ 1.7047521   1.6330549   1.5622069  ...  0.6491856   0.6255697\n     0.5748326 ]\n   [ 1.8702583   1.7547996   1.675536   ...  1.0183368   1.0538664\n     0.8186456 ]]]\n\n\n [[[ 0.7983964   0.04580656  1.8015926  ...  2.3787677   2.4304667\n     2.5549335 ]\n   [ 0.11447658  0.16611814  1.5299362  ...  2.3324823   2.5311995\n     2.517113  ]\n   [-0.3254986   0.04914963  0.4987295  ...  2.4113958   2.5702276\n     2.5359013 ]\n   ...\n   [ 1.924833    1.2690383   1.7126051  ... -1.9872904  -1.6598388\n    -1.5429176 ]\n   [ 1.9272162   2.1122444   0.81173795 ... -2.266419   -1.9612812\n    -1.7212816 ]\n   [ 1.598059    1.7017672   0.5824907  ... -2.172423   -2.3452392\n    -2.0695052 ]]\n\n  [[ 1.0473913   0.17728084  1.9214034  ...  2.762773    2.7139175\n     2.6397183 ]\n   [ 0.40489873  0.35697126  1.6447845  ...  2.6580281   2.7227774\n     2.5443604 ]\n   [-0.03767626  0.2568605   0.60306793 ...  2.6456127   2.70626\n     2.6058192 ]\n   ...\n   [ 1.6670712   0.9197272   1.3441175  ... -1.7633717  -1.4282305\n    -1.2699018 ]\n   [ 1.7175968   1.8002511   0.33927855 ... -2.085835   -1.7733356\n    -1.4718362 ]\n   [ 1.3055017   1.3611637   0.14160866 ... -1.9897406  -2.1664145\n    -1.8845258 ]]\n\n  [[ 0.4295846  -0.5118642   1.1741238  ...  2.9240546   2.9754434\n     2.97678   ]\n   [-0.37937564 -0.46503386  0.84083176 ...  2.7271674   2.9661815\n     2.938287  ]\n   [-0.77998525 -0.46305233 -0.08057912 ...  2.7064786   2.9183838\n     2.9450963 ]\n   ...\n   [ 1.6786813   0.98479605  1.4091414  ... -1.3182743  -1.0091492\n    -0.8901495 ]\n   [ 1.6978557   1.8367176   0.41331437 ... -1.6265131  -1.3159506\n    -1.0716844 ]\n   [ 1.2687788   1.399399    0.16117825 ... -1.5308458  -1.7067347\n    -1.4260987 ]]]\n\n\n [[[ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   ...\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]]\n\n  [[ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   ...\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]]\n\n  [[ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   ...\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]\n   [ 0.          0.          0.         ...  0.          0.\n     0.        ]]]]\n<NDArray 5x3x416x416 @cpu_shared(0)>, \n[[[  0.         0.       416.       416.        14.         0.      ]\n  [ -1.        -1.        -1.        -1.        -1.        -1.      ]\n  [ -1.        -1.        -1.        -1.        -1.        -1.      ]\n  [ -1.        -1.        -1.        -1.        -1.        -1.      ]]\n\n [[  0.832     23.296    319.488    414.89066   15.         0.      ]\n  [285.376      0.       416.       277.33334   15.         0.      ]\n  [ -1.        -1.        -1.        -1.        -1.        -1.      ]\n  [ -1.        -1.        -1.        -1.        -1.        -1.      ]]\n\n [[164.3871   180.97885  286.       351.90332    1.         0.      ]\n  [151.80646   89.23263  269.2258   340.59213   14.         0.      ]\n  [ -1.        -1.        -1.        -1.        -1.        -1.      ]\n  [ -1.        -1.        -1.        -1.        -1.        -1.      ]]\n\n [[  0.        18.851963 375.61166  402.17523   18.         0.      ]\n  [ -1.        -1.        -1.        -1.        -1.        -1.      ]\n  [ -1.        -1.        -1.        -1.        -1.        -1.      ]\n  [ -1.        -1.        -1.        -1.        -1.        -1.      ]]\n\n [[175.32394  143.74522  250.14084  218.59872    9.         0.      ]\n  [265.9155   143.08281  291.15494  208.66241    9.         0.      ]\n  [196.05634  131.82166  252.84508  203.36305    9.         0.      ]\n  [245.6338   139.7707   274.92957  194.08917    9.         0.      ]]]\n<NDArray 5x4x6 @cpu_shared(0)>)",
      "\n",
      "\ndata 0:",
      " ",
      "(3, 416, 416)",
      " ",
      "label 0:",
      " ",
      "(4, 6)",
      "\n",
      "data 1:",
      " ",
      "(3, 416, 416)",
      " ",
      "label 1:",
      " ",
      "(4, 6)",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for ib, batch in enumerate(train_loader):\n",
    "    if ib > 0:\n",
    "        break\n",
    "    print(\"batch: \\n\", batch)\n",
    "    print('\\ndata 0:', batch[0][0].shape, 'label 0:', batch[1][0].shape)\n",
    "    print('data 1:', batch[0][1].shape, 'label 1:', batch[1][1].shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ids: ",
      " ",
      "(1, 100, 1)",
      "\n",
      "scores: ",
      " ",
      "(1, 100, 1)",
      "\n",
      "bboxes: ",
      " ",
      "(1, 100, 4)",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from gluoncv import model_zoo\n",
    "net = model_zoo.get_model('yolo3_darknet53_voc', pretrained_base=False)\n",
    "\n",
    "import mxnet as mx\n",
    "x = mx.nd.zeros(shape=(1, 3, 416, 416))\n",
    "net.initialize()\n",
    "cids, scores, bboxes = net(x)\n",
    "\n",
    "print(\"ids: \", cids.shape)\n",
    "print(\"scores: \", scores.shape)\n",
    "print(\"bboxes: \", bboxes.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "batch[0][0]:",
      " ",
      "(3, 416, 416)",
      "\n",
      "batch[1][0]:",
      " ",
      "(10647, 1)",
      "\n",
      "batch[2][0]:",
      " ",
      "(10647, 2)",
      "\n",
      "batch[3][0]:",
      " ",
      "(10647, 2)",
      "\n",
      "batch[4][0]:",
      " ",
      "(10647, 2)",
      "\n",
      "batch[5][0]:",
      " ",
      "(10647, 20)",
      "\n",
      "batch[6][0]:",
      " ",
      "(11, 4)",
      "\n",
      "obj_loss: ",
      " ",
      "(5,)",
      "\n",
      "center_loss: ",
      " ",
      "(5,)",
      "\n",
      "scale_loss: ",
      " ",
      "(5,)",
      "\n",
      "cls_loss: ",
      " ",
      "(5,)",
      "\n",
      "batch[0][0]:",
      " ",
      "(3, 416, 416)",
      "\n",
      "batch[1][0]:",
      " ",
      "(10647, 1)",
      "\n",
      "batch[2][0]:",
      " ",
      "(10647, 2)",
      "\n",
      "batch[3][0]:",
      " ",
      "(10647, 2)",
      "\n",
      "batch[4][0]:",
      " ",
      "(10647, 2)",
      "\n",
      "batch[5][0]:",
      " ",
      "(10647, 20)",
      "\n",
      "batch[6][0]:",
      " ",
      "(7, 4)",
      "\n",
      "obj_loss: ",
      " ",
      "(5,)",
      "\n",
      "center_loss: ",
      " ",
      "(5,)",
      "\n",
      "scale_loss: ",
      " ",
      "(5,)",
      "\n",
      "cls_loss: ",
      " ",
      "(5,)",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from mxnet import autograd\n",
    "train_transform = presets.yolo.YOLO3DefaultTrainTransform(width, height, net)\n",
    "# return stacked images, objectness_targets, center_targets, scale_targets, gradient weights, class_targets\n",
    "# additionally, return padded ground truth bboxes, so there are 7 components returned by dataloader\n",
    "batchify_fn = Tuple(*([Stack() for _ in range(6)] + [Pad(axis=0, pad_val=-1) for _ in range(1)]))\n",
    "train_loader = DataLoader(train_dataset.transform(train_transform), batch_size, shuffle=True,\n",
    "                          batchify_fn=batchify_fn, last_batch='rollover', num_workers=num_workers)\n",
    "\n",
    "for ib, batch in enumerate(train_loader):\n",
    "    if ib > 1:\n",
    "        break\n",
    "\n",
    "    print('batch[0][0]:', batch[0][0].shape)  # (3, h, w)\n",
    "    print('batch[1][0]:', batch[1][0].shape)  # (10647, 1)\n",
    "    print('batch[2][0]:', batch[2][0].shape)  # (10647, 2)\n",
    "    print('batch[3][0]:', batch[3][0].shape)  # (10647, 2)\n",
    "    print('batch[4][0]:', batch[4][0].shape)  # (10647, 2)\n",
    "    print('batch[5][0]:', batch[5][0].shape)  # (10647, 20)\n",
    "    print('batch[6][0]:', batch[6][0].shape)  # label (num_obj, 4)\n",
    "    with autograd.record():\n",
    "        input_order = [0, 6, 1, 2, 3, 4, 5]\n",
    "        obj_loss, center_loss, scale_loss, cls_loss = net(*[batch[o] for o in input_order])\n",
    "        \n",
    "        print(\"obj_loss: \", obj_loss.shape)  # (2, )\n",
    "        print(\"center_loss: \", center_loss.shape)  # (2, )\n",
    "        print(\"scale_loss: \", scale_loss.shape)  # (2, )\n",
    "        print(\"cls_loss: \", cls_loss.shape)  # (2, )\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}